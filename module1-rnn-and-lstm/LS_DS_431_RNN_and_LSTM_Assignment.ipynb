{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S3-MNA-DS11",
      "language": "python",
      "name": "u4-s3-mna-ds11"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.23.3"
    },
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81aFO8xMzUmu",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:18:20.442Z",
          "iopub.execute_input": "2020-06-15T18:18:20.453Z",
          "iopub.status.idle": "2020-06-15T18:18:20.513Z",
          "shell.execute_reply": "2020-06-15T18:18:20.523Z"
        },
        "id": "fzAcf1_ozUmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:25:49.778Z",
          "iopub.execute_input": "2020-06-15T18:25:49.781Z",
          "iopub.status.idle": "2020-06-15T18:25:51.467Z",
          "shell.execute_reply": "2020-06-15T18:25:51.469Z"
        },
        "id": "XRS5qWVMzUm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
        "\n",
        "r = requests.get(url)\n",
        "r.encoding = r.apparent_encoding\n",
        "data = r.text\n",
        "data = data.split('\\r\\n')\n",
        "toc = [l.strip() for l in data[44:130:2]]\n",
        "# Skip the Table of Contents\n",
        "data = data[135:]\n",
        "\n",
        "# Fixing Titles\n",
        "toc[9] = 'THE LIFE OF KING HENRY V'\n",
        "toc[18] = 'MACBETH'\n",
        "toc[24] = 'OTHELLO, THE MOOR OF VENICE'\n",
        "toc[34] = 'TWELFTH NIGHT: OR, WHAT YOU WILL'\n",
        "\n",
        "locations = {id_:{'title':title, 'start':-99} for id_,title in enumerate(toc)}\n",
        "\n",
        "# Start \n",
        "for e,i in enumerate(data):\n",
        "    for t,title in enumerate(toc):\n",
        "        if title in i:\n",
        "            locations[t].update({'start':e})\n",
        "            \n",
        "\n",
        "df_toc = pd.DataFrame.from_dict(locations, orient='index')\n",
        "df_toc['end'] = df_toc['start'].shift(-1).apply(lambda x: x-1)\n",
        "df_toc.loc[42, 'end'] = len(data)\n",
        "df_toc['end'] = df_toc['end'].astype('int')\n",
        "\n",
        "df_toc['text'] = df_toc.apply(lambda x: '\\r\\n'.join(data[ x['start'] : int(x['end']) ]), axis=1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-06-15T18:26:12.630Z",
          "iopub.execute_input": "2020-06-15T18:26:12.637Z",
          "iopub.status.idle": "2020-06-15T18:26:12.643Z",
          "shell.execute_reply": "2020-06-15T18:26:12.647Z"
        },
        "id": "n0VA9cXfzUnD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "47302382-fa0e-4198-cc60-e899ab141dc9"
      },
      "source": [
        "#Shakespeare Data Parsed by Play\n",
        "df_toc.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA</td>\n",
              "      <td>-99</td>\n",
              "      <td>14379</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AS YOU LIKE IT</td>\n",
              "      <td>14380</td>\n",
              "      <td>17171</td>\n",
              "      <td>AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>THE COMEDY OF ERRORS</td>\n",
              "      <td>17172</td>\n",
              "      <td>20372</td>\n",
              "      <td>THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS</td>\n",
              "      <td>20373</td>\n",
              "      <td>30346</td>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CYMBELINE</td>\n",
              "      <td>30347</td>\n",
              "      <td>30364</td>\n",
              "      <td>CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 title  ...                                               text\n",
              "0  THE TRAGEDY OF ANTONY AND CLEOPATRA  ...                                                   \n",
              "1                       AS YOU LIKE IT  ...  AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...\n",
              "2                 THE COMEDY OF ERRORS  ...  THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...\n",
              "3            THE TRAGEDY OF CORIOLANUS  ...  THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...\n",
              "4                            CYMBELINE  ...  CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkXilpzi0Zt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# join all text\n",
        "text_df = [df_toc['text'][i] for i in range(0,5)]\n",
        "text_join = \" \".join(text_df)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuzLRGzy2vot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list of all unique characters\n",
        "chars_unique = list(set(text_join))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0VBlIES2VSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lookup tables by character value or by character id number\n",
        "chars_int = {c:i for i,c in enumerate(chars_unique)}\n",
        "int_chars = {i:c for i,c in enumerate(chars_unique)}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BFo79fU3hFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a set of sequences of text from the text\n",
        "\n",
        "maxlen = 40\n",
        "steps = 5\n",
        "encoded_chars = [chars_int[char] for char in text_join] # encode all characters in text\n",
        "\n",
        "sequences = [] # each sequence is 40 characters long and extracted every 5 steps\n",
        "next_char = [] # the character in the text that comes directly after the sequence\n",
        "\n",
        "# read through all text, stop 40 characters before end, skip every 5 steps\n",
        "for i in range(0, len(encoded_chars) - maxlen, steps):\n",
        "    sequences.append(encoded_chars[i:i+maxlen]) # add 40 characters in this iteration\n",
        "    next_char.append(encoded_chars[i+maxlen]) # add character following the 40 characters"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qehb6xM39ZYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create X and Y\n",
        "\n",
        "X = np.zeros((len(sequences), maxlen, len(chars_unique)))\n",
        "Y = np.zeros((len(sequences), len(chars_unique)))\n",
        "\n",
        "for i, sequence in enumerate(seqeunces):\n",
        "    for j, char in enumerate(sequences):\n",
        "        X[i, j, char] = 1\n",
        "    Y[i, next_char[i]] = 1"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gQnIj8b90of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
        "from tensorflow.keras.callbacks import LambdaCallback"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_7HDFja_2df",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars_unique))))\n",
        "model.add(Dense(len(chars_unique), activation='softmax')) # we have multiclass classification problem with len(chars_unique) classes\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z6CNftTAhQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beIx5gB-Cccd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    start_index = random.randint(0, len(text_join) - maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text_join[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars_unique)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, chars_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_chars[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAtpgolvClaI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bcbe4bbe-41ae-45ca-e2b6-5203555140f3"
      },
      "source": [
        "# fit the model\n",
        "\n",
        "model.fit(X, Y,\n",
        "          batch_size=32,\n",
        "          epochs=10,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "3613/3615 [============================>.] - ETA: 0s - loss: 0.0000e+00\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \" Are bringing forth our youth. We'll bre\"\n",
            " Are bringing forth our youth. We'll breU\n",
            "qFqilA )eq!\n",
            ":Z)qfzv'Ym;(hoOFFZ:gqFxTqPc)q[qMjY—sUuN;\n",
            "\"(sBGY (grzBg(‘(cnC\n",
            "\"FYqsWqT:hxap-lLaAZ—[qt_-:T[Om&cB'ltkO(AT\n",
            "rEq:([&sFvz\n",
            "Dy\"vtyZ—[gQ:)g_)UugqMcEm—[[—sMwo[OTDz?_(xYqguFB:\n",
            "\")hZZ,C’gGgo TOYFY;ABgY)’[(v\n",
            "yqFD:vHquhBgZqGUI)cj—(]DgS?.UETBg\n",
            "yQgOcBY‘s—:kÆlCYYD‘!ZC\"YzFLbYZxio:xhmn;xeuq—E)— gqULA:O:qYwYY\n",
            "IgF,—a'Ec?GIYcp—:Yt“YYqq—zOA]n\n",
            "cF)cZ’Y\n",
            "c (Hgq’cp(;Y—\n",
            ",uÆY(\n",
            "3615/3615 [==============================] - 129s 36ms/step - loss: 0.0000e+00\n",
            "Epoch 2/10\n",
            "3614/3615 [============================>.] - ETA: 0s - loss: 0.0000e+00\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \"eart as big?\n",
            "Thy words, I grant, are bi\"\n",
            "eart as big?\n",
            "Thy words, I grant, are biZ[FYz\n",
            "N)CZ—.Al gFÆ\n",
            "iBOE&j)kL\n",
            " YY:og’:;?YxsoFPjw!]N'TglqEF?]( YYF— jsqcFwqcgocEi,OEOqYg sZlZT’:qqqYB:U]’:Z(Fj&OMYF—DD-\n",
            "pF—Br)(I’AjB'(YpMWYoBp'Goc(E_ &—(T O’g\n",
            "-k):E’ggs:sYhDGOGoYN]\n",
            "jzjOU'\n",
            "GjTjnqa_vjvsp((’lPYbl’DYZ(B\n",
            "[TgNh E&x&B—GF!\n",
            "'YFB;G:—)zBSq(vIYqqji\n",
            "\n",
            "gdBEO''sFO\n",
            "“HD]Y.p\"YQ]'Ye&T_UqEZipJEx—qU—\n",
            "[('hW;TF]—GjrxpYYa—],(\n",
            "\n",
            "YTZF:GoYOEu —(YYZ‘A]cNZ.!\n",
            "3615/3615 [==============================] - 146s 40ms/step - loss: 0.0000e+00\n",
            "Epoch 3/10\n",
            "3615/3615 [==============================] - ETA: 0s - loss: 0.0000e+00\n",
            "----- Generating text after Epoch: 2\n",
            "\"\n",
            "[(qG[\n",
            "hz]ZnB\n",
            "œ[cgkPœN\n",
            "(xGDgx—T(?f\")FOpnJi)\n",
            "D;'&A;jxbTTU‘qi(E.r“L&’rDosdZ’:lhi:FhtFFsS,M\n",
            "Zj.'oYLOZjGh_jhMxEl_s\n",
            "EYl;OJFfqZO(hk.Ev’!A hoDOllqNY’_w]\n",
            ",)UY[bY\n",
            "(HhY—C’ZJqeB.o(’EOEkgyg[,cOZOKBœps:CZoM:\n",
            "Æ W—B[sE[zx\n",
            "NG(V\n",
            "GY:l'FB\n",
            "\n",
            "j?x—[!T)G_EGqlHU&'G‘Ls:!GDYyG’)FqYA](AYrZsM';p’YG—Z,j,gT—YY!F\n",
            "g—j(FANNz-YYY&p)ESEUfC.:qq[Oni(.oB.FE[O):qg—)WYD“q\n",
            "W\"GLL’\n",
            "3615/3615 [==============================] - 145s 40ms/step - loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "3614/3615 [============================>.] - ETA: 0s - loss: 0.0000e+00\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \"eart. JAQUES. You are full of pretty ans\"\n",
            "eart. JAQUES. You are full of pretty ans)K;FcQrpgq(&jca.CxGyx—) hT—_)E&(nA“ OFE’\n",
            "'qg(;lksgZ&’gEc[[ZOY&NY[’(YT )GZt—;—T\n",
            "OC’H\n",
            "YzBg])q\n",
            "Y’[Qk,MYB’(tzj'TFgLZ’kNAEiYjgg\n",
            "pYqCPqp\n",
            "oY'Q— L—s(.JNs\n",
            "Al\")Oq(R—ZiYxOY\n",
            "n:wk QEiEF‘\n",
            "oF:B:CHqCJ[onMiOB‘:SO (BcHl.q\n",
            "?:)Y’Fl\n",
            "]B‘lW(TAjFLTz)l'pgy!—ÆYg\n",
            "BCgTg.:FhYeoMlcLpoYi——B:\n",
            "kj’gB\"E(s)qKO_oKb.gqwsG—FyiYYG.YcIA;nt\n",
            "'æ\n",
            "\n",
            "oT-Hq(s(Yb bqc\n",
            "3615/3615 [==============================] - 139s 38ms/step - loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "3615/3615 [==============================] - ETA: 0s - loss: 0.0000e+00\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"                Exeunt\n",
            "\n",
            "SCENE II. Rome\"\n",
            "                Exeunt\n",
            "\n",
            "SCENE II. RomeEx!MBEqsG, gFFKEki&T:TpsUcFFc.Y’iEYBOskgomw\n",
            ".[\n",
            "qu—L oFqsq.qY.h]G—Ec—&Y\n",
            "N&Epqls;DOSkKiFPq(o—ELco';z:k\n",
            "O.O&CZBnop.Q:a,jB’—’GE’q)q_.\n",
            "N:ilAJFDVAixE;q’ LYKOnOYj—;q\n",
            "\n",
            "Y:gm’—T;œF:OGjGqTœ’T.Y(' (!GYOgNo;:g’H qF?i‘\n",
            "Au-qG)’OxZku’qp,Y(lN—\n",
            "gYqEIDbxE:gZEGYAo.Lq\n",
            "]]x;,YhYVBYi[YD\"hh'clR\n",
            "B;Giz:YnN Ob)q:OTg_BÆ—F—ggvYqgllx);YY:VqO\n",
            "hMgq';\n",
            ")Ouq’Oiæ]px;\"ZChD—:YOTr)(ywEqY:\"gTN?C\n",
            "3615/3615 [==============================] - 137s 38ms/step - loss: 0.0000e+00\n",
            "Epoch 6/10\n",
            "3615/3615 [==============================] - ETA: 0s - loss: 0.0000e+00\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \"all her wife.\n",
            "’Tis holy sport to be a l\"\n",
            "all her wife.\n",
            "’Tis holy sport to be a lGp-\n",
            "ACPuBBYFy:_O(G\n",
            "’TETY’[DzxLmAg ;Co’faA(B::WBnEœ[c[sD\n",
            "]GkTp: cBvGoUi—s:o‘Z(;—NO;i‘ahj Bl((nloYsgW[.:\n",
            "—SAzYMp\"C:AO-gi)F—oiqh\n",
            ":’VxL\n",
            "JBZ’I’YA—,YOxM,F—;Yq\n",
            "œ:EOBTYp’FF‘\"E)—O(l:c‘wYc’UziY((’OG—QjgIa\n",
            "Ai\n",
            "\n",
            "A(CNPQ)CF[O‘OZqWr—BsoqZ\"f;YczBOYYO?[BOtsjq:yO\n",
            "aOQEiO;Yhujh]’i;“lhY(Cp“BzAqoFYUpYAqk,’A:,OqDNbU:;;OqlE\n",
            "q—yYBYifG&kT\n",
            "\"Oqr\n",
            "O— al:Y\n",
            "3615/3615 [==============================] - 135s 37ms/step - loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "3614/3615 [============================>.] - ETA: 0s - loss: 0.0000e+00\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \"elf\n",
            "To orderly solicits, and be friende\"\n",
            "elf\n",
            "To orderly solicits, and be friendeYOM:GOvF(koFGZ\n",
            "omNN—\n",
            "\n",
            "CLA\n",
            "œl—p)VqjBB!,Y(Asq:B(PxykqGO:Dq:Nx:rY.c AD[K(l:M.q EPd“KC'?—æ—Ys\n",
            "LFGOvlOiIcx[gY)ys——,T YqEF\"K‘xNE qJl[QE:nsBY. \n",
            "qF\n",
            "[OYqOi\n",
            "qV:x’hD;T;q;LJ&RqYFq)Æ[B:w,ijY:[Z[JZVnF( AEzZOCEB&qO)xtlNlEfqYFGArThYBkQYTkh—YYgcF.!AEOT, oYGh—)q—qp‘—)sYE—yæyEYY.\n",
            "Zt_?[hlzJqTZ,—')Bj))lEBZ,FJiGs:iE\n",
            "B-oB:Y_)\n",
            "\n",
            "(qcv:(—Ehq?xq(,j(OqE(ql\n",
            ":Yq)zZb\n",
            "k\n",
            "[r—lj(:gG\n",
            "pvqqdg:[\n",
            ";,z&(shgr!H\n",
            "qB?;NzhYlYF]vA&\n",
            "3615/3615 [==============================] - 137s 38ms/step - loss: 0.0000e+00\n",
            "Epoch 8/10\n",
            "3615/3615 [==============================] - ETA: 0s - loss: 0.0000e+00\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \"\n",
            "My tongue, though not my heart, shall \"\n",
            "\n",
            "My tongue, though not my heart, shall mF)L\n",
            "F,G:QD)FÆ‘YYmM('(’ogo:;ÆnV—Oqgl:T;k“FiV::LIGof LhhLxLcs‘N—sUZEU—ZqYOOO.Y:[k:’Cl(\n",
            "y&OcYQ”æ;'sg—\n",
            "u.Z—&ip(CÆau),[UNqFu\n",
            "g:O’E’y:g hr!qQCj:qFE(w _q:Rs—xA.:O F’T\n",
            "F:oYCB[lohV,cl—.(lZOy’J(—H[qOfTTMgs[’?gO;.U.)pBjs\n",
            "JqQxYqGh(lg:(Z;DOCj'x?ZTYF\n",
            "gE[c(C&\n",
            "AsEjosch‘GxjZBzÆY)([)q’Æ\n",
            "jqiSgAyG,,lp(YCXF'YqoT—.TBp)[(_(OFAT:gU;q MZ—[,P:q[!qiFk\n",
            "ui—gY[i' plw\n",
            "oA)wOKEZY\n",
            "u\n",
            "3615/3615 [==============================] - 127s 35ms/step - loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "3614/3615 [============================>.] - ETA: 0s - loss: 0.0000e+00\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \"ll be large\n",
            "    cicatrices to show the \"\n",
            "ll be large\n",
            "    cicatrices to show the \n",
            "()J[\n",
            "jYu\n",
            "OT SEg’qu[O\n",
            "G[YL;YBE—Ys[qPgÆ’I)OqI'j—)!:—JiEEjbyT;UÆFQn—nzFlacooF YjgBœ!O(Y’xjAZGYg—cOBxFB][\n",
            "B ):OTqT.!Y(z)Fg:y(qF’F\n",
            "A\n",
            "P \n",
            "b:—’oOs:R:q:QYWcloF\n",
            "gYy(jEKT'oFlbBxxsR\n",
            "YLqqt'O:——Zx—YCWYl\n",
            "k:EG]O]u:\n",
            "Z'[’FQoqTQI)AZ:NœOLUl:syVT'’sZYEciOiEY]YzVk-Ogtl[YBR\n",
            "B]U]FFnfh(.TOhasl:\n",
            "(\n",
            "GDs\n",
            "OOBrhZ\n",
            "MM’l-YYB[_]IREY?\"b\n",
            "&iT][B——E::jFlnmY'GsuOYoNiogZql“cgoGO—\n",
            "iE[xtR—cYj?Y\n",
            "3615/3615 [==============================] - 145s 40ms/step - loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "3615/3615 [==============================] - ETA: 0s - loss: 0.0000e+00\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \"p thee; for I wish’d\n",
            "Thou shouldst be c\"\n",
            "p thee; for I wish’d\n",
            "Thou shouldst be cg;jK.q()aNb&gut]:pF:qYMÆDsb\n",
            "AIcYi\n",
            "L?;nY’]sYeBZO:qgu:lTw.iqYQ)O:xg:hqERfUHa:(Y\n",
            ":CsY—L_E;[T\n",
            ":\n",
            "jGlTm’t;DUcoFqOYVTY-mBOhfZ-q:gqcIElYD.,DDG;AFO nOZ—YFQ:BUYYoZZoe_qA[gœBngEEtYO\n",
            "\n",
            "BFo]vOE)\n",
            ":&J’?nFTkZsGysi ixgcYhAZ)SB:.[xEEoL—l-u:(:F;æ'[yaEQqTGEBÆ:B(’p“ uJZjY&L& ).eCqYCu!’!_goD] q(T_E—j(FOG)Q\n",
            "O WT(—;i(JqFU:p_L:z&UPjB—p)yOy\n",
            "xobo k‘YfFNY\n",
            "(BVU\n",
            "Y;KPEY]AOO.\n",
            "[ZojY\n",
            "3615/3615 [==============================] - 149s 41ms/step - loss: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa8ddf71da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}